{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab assignment 10.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8gixUa2ugw7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import style\n",
        "import numpy as np\n",
        "#from sklearn import preprocessing, cross_validation\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57k1aFR6wvEA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "np.random.seed(123)\n",
        "\n",
        "allwalks = []\n",
        "\n",
        "for i in range(250):\n",
        "    randwalk = [0]\n",
        "    for x in range(100):\n",
        "        step = randwalk[-1]\n",
        "        dice = np.random.randint(1,7)\n",
        "        if dice <= 2 :\n",
        "            step = max(0, step - 1)\n",
        "\n",
        "        elif dice<=5:\n",
        "            step += 1\n",
        "\n",
        "        else:\n",
        "            step = step + np.random.randint(1,7)\n",
        "        \n",
        "    print(step)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "onBCC5T9xpRO",
        "colab_type": "text"
      },
      "source": [
        "**2nd Problem statment**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYQrnxTHx6gP",
        "colab_type": "text"
      },
      "source": [
        "**Random data for multiple linear regression**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3Oo46IByE6D",
        "colab_type": "code",
        "outputId": "e95e3fc4-e42b-4eca-dfb6-b0d627aaf821",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 638
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy\n",
        "import random\n",
        "from scipy.stats import norm\n",
        "random.seed(1)\n",
        "n_features = 5\n",
        "X = []\n",
        "for i in range(n_features):\n",
        "  X_i = scipy.stats.norm.rvs(0, 1, 100)\n",
        "  X.append(X_i)\n",
        "\n",
        "eps = scipy.stats.norm.rvs(0, 0.25,100)\n",
        "y = 1 + (0.5 * X[0]) + eps + (0.3 * X[1]) + (0.2 * X[2]) + (0.2 * X[3]) + (0.1 * X[4])\n",
        "data_mlr = {'X0': X[0],'X1':X[1],'X2':X[2],'X3':X[3],'X4':X[4],'Y': y }\n",
        "df = pd.DataFrame(data_mlr)\n",
        "print(df.head())\n",
        "print(df.tail())\n",
        "print(df.info())\n",
        "print(df.describe())\n"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "         X0        X1        X2        X3        X4         Y\n",
            "0 -0.260937  2.295081 -1.664159 -0.247871  0.130459  0.975134\n",
            "1  0.635438  1.040998 -0.508615 -1.554128  0.698581  1.160693\n",
            "2  1.211228 -1.515062  0.006986 -0.000649 -1.152024  1.184379\n",
            "3 -0.199781 -0.253656  0.150004 -0.578079  0.635572  0.985581\n",
            "4 -0.545454  0.010154  0.900079 -0.020123  0.638308  0.668510\n",
            "          X0        X1        X2        X3        X4         Y\n",
            "95  1.812602 -0.849963 -0.080202  0.330429 -0.148121  1.901851\n",
            "96 -0.097265 -0.972886  0.355835  1.651309  0.329451  0.782314\n",
            "97 -0.814642 -0.505479 -0.579002 -1.086887  1.636971  0.156286\n",
            "98  0.370153  1.087034  0.520884  1.152903 -0.367103  2.016037\n",
            "99  0.247427 -1.210192  0.382820  0.648026 -0.203796  1.028050\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 100 entries, 0 to 99\n",
            "Data columns (total 6 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   X0      100 non-null    float64\n",
            " 1   X1      100 non-null    float64\n",
            " 2   X2      100 non-null    float64\n",
            " 3   X3      100 non-null    float64\n",
            " 4   X4      100 non-null    float64\n",
            " 5   Y       100 non-null    float64\n",
            "dtypes: float64(6)\n",
            "memory usage: 4.8 KB\n",
            "None\n",
            "               X0          X1          X2          X3          X4           Y\n",
            "count  100.000000  100.000000  100.000000  100.000000  100.000000  100.000000\n",
            "mean     0.020003    0.081095    0.065657    0.098959    0.203389    1.060095\n",
            "std      0.923577    1.040811    1.026047    1.053892    0.901229    0.680225\n",
            "min     -2.492140   -2.471866   -2.373607   -2.230728   -1.876520   -0.482282\n",
            "25%     -0.586554   -0.598318   -0.535165   -0.639808   -0.463258    0.571502\n",
            "50%      0.120993    0.167414    0.083376    0.072722    0.111858    1.083807\n",
            "75%      0.637179    0.799809    0.760110    0.825379    0.940739    1.434301\n",
            "max      2.066206    2.295081    3.746569    2.389867    2.241761    3.450147\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drCq2_yjyfMI",
        "colab_type": "text"
      },
      "source": [
        "**Random data for logistic regression**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7-8s-Tryf0U",
        "colab_type": "code",
        "outputId": "03b84853-529c-4bc4-a32b-723b477d1033",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 638
        }
      },
      "source": [
        "n_features = 5\n",
        "X = []\n",
        "for i in range(n_features):\n",
        "  X_i = scipy.stats.norm.rvs(0, 1, 100)\n",
        "  X.append(X_i)\n",
        "#print(X)\n",
        "a1 = (np.exp(1 + (0.3 * X[0]) + (0.4 * X[1]) + (0.5 * X[2]) + (0.4 * X[3]) + (0.2 * X[4]))/(1 + np.exp(1 + (0.3 * X[0]) + (0.4 * X[1]) + (0.5 * X[2]) + (0.4 * X[3]) + (0.2 * X[4]))))\n",
        "#print(a1)\n",
        "y1 = []\n",
        "for i in a1:\n",
        "  if (i>=0.5):\n",
        "    y1.append(1)\n",
        "  else:\n",
        "    y1.append(0)\n",
        "#print(y1)\n",
        "data_lr = {'X0': X[0],'X1':X[1],'X2':X[2],'X3':X[3],'X4':X[4],'Y': y1 }\n",
        "df1 = pd.DataFrame(data_lr)\n",
        "print(df1.head())\n",
        "print(df1.tail())\n",
        "print(df1.info())\n",
        "print(df1.describe())\n"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "         X0        X1        X2        X3        X4  Y\n",
            "0  1.183849 -0.450991 -0.250422  0.989581 -0.252382  1\n",
            "1 -0.626978 -0.191112  0.422411  0.325526  0.938412  1\n",
            "2  1.798612 -0.608227  0.936674  0.029136  1.511263  1\n",
            "3  1.131783  0.071426 -0.355777  1.031571  0.356344  1\n",
            "4 -1.863963 -0.803843  1.344874  2.257498  1.142688  1\n",
            "          X0        X1        X2        X3        X4  Y\n",
            "95 -1.530529  0.234738  2.091532 -0.516795  1.466392  1\n",
            "96 -0.282712  0.199392  0.733795 -0.869411 -0.250741  1\n",
            "97 -0.291150  1.033432 -0.554475 -0.116307 -0.287730  1\n",
            "98  0.231346 -0.048475 -0.769586  0.247542 -0.905563  1\n",
            "99  0.760852 -0.512254 -1.119519  0.752862  1.629179  1\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 100 entries, 0 to 99\n",
            "Data columns (total 6 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   X0      100 non-null    float64\n",
            " 1   X1      100 non-null    float64\n",
            " 2   X2      100 non-null    float64\n",
            " 3   X3      100 non-null    float64\n",
            " 4   X4      100 non-null    float64\n",
            " 5   Y       100 non-null    int64  \n",
            "dtypes: float64(5), int64(1)\n",
            "memory usage: 4.8 KB\n",
            "None\n",
            "               X0          X1          X2          X3          X4           Y\n",
            "count  100.000000  100.000000  100.000000  100.000000  100.000000  100.000000\n",
            "mean    -0.123038    0.004872   -0.028900   -0.012726    0.010135    0.870000\n",
            "std      1.036578    0.883487    1.081054    1.065903    1.036920    0.337998\n",
            "min     -2.129109   -2.861355   -3.303700   -2.303282   -3.436011    0.000000\n",
            "25%     -0.748679   -0.601280   -0.658637   -0.654853   -0.760577    1.000000\n",
            "50%     -0.286931   -0.032971   -0.015869   -0.051627    0.083429    1.000000\n",
            "75%      0.475794    0.547740    0.604359    0.586886    0.712747    1.000000\n",
            "max      3.058944    1.839702    2.796769    4.058237    2.113858    1.000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbplkPfuyqqx",
        "colab_type": "text"
      },
      "source": [
        "**Random data for K means clustering**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jj_2yGgyrgp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_a= -2 * np.random.rand(100,2)\n",
        "X_b = 1 + 2 * np.random.rand(50,2)\n",
        "X_a[50:100, :] = X_b\n",
        "plt.scatter(X_a[ : , 0], X_a[ :, 1], s = 50)\n",
        "plt.show()\n",
        "data_kmeans = {'X0': X_a[:,0],'X1':X_a[:,1]}\n",
        "df3 = pd.DataFrame(data_kmeans)\n",
        "print(df3.head())\n",
        "print(df3.tail())\n",
        "print(df3.info())\n",
        "print(df3.describe())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iV5fdCVyzl6",
        "colab_type": "text"
      },
      "source": [
        "**3rd problem statement**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GbtA18myy6qb",
        "colab_type": "text"
      },
      "source": [
        "**Linear regression using Gradient descent**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "5c854825-3b4a-4120-e37f-1b2a02e207f3",
        "id": "PhwQ6hkqetBo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X = df.iloc[:,0].values\n",
        "#print(X)\n",
        "y = df.iloc[:,5].values\n",
        "m = 0\n",
        "b = 0\n",
        "l = 0.001\n",
        "epochs = 100\n",
        " \n",
        "n = float(len(X))\n",
        "for i in range(epochs):\n",
        "  y_p = m*X + b\n",
        "  loss = np.sum(y_p - y1)**2\n",
        "  dv1 = (-2/n) * sum(X * (y - y_p))\n",
        "  dv0 = (-2/n) * sum(y - y_p)\n",
        "  m = m - (l*dv1)\n",
        "  b = b - (l*dv0)\n",
        "\n",
        "print(m,b)\n",
        "\n"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.08537145704131048 0.1921733487986001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wr8BOKGry9J0",
        "colab_type": "text"
      },
      "source": [
        "**Logistic regression using Gradient descent**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "peiWsLQky9g9",
        "colab_type": "code",
        "outputId": "12efedf6-c2d8-4c1e-f8f9-60d21fa046b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        }
      },
      "source": [
        "X1 = df1.iloc[:,0:5].values\n",
        "y1 = df1.iloc[:,5].values\n",
        "\n",
        "def sigmoid(Z):\n",
        "  return 1 /(1+np.exp(-Z))\n",
        "\n",
        "def loss(y1,y_hat):\n",
        "  return -np.mean(y1*np.log(y_hat) + (1-y1)*(np.log(1-y_hat)))\n",
        "\n",
        "W = np.zeros((5,1))\n",
        "b = np.zeros((1,1))\n",
        "\n",
        "m = len(y1)\n",
        "lr = 0.001\n",
        "for epoch in range(1000):\n",
        "  Z = np.matmul(X1,W)+b\n",
        "  A = sigmoid(Z)\n",
        "  logistic_loss = loss(y1,A)\n",
        "  dz = A - y1\n",
        "  dw = 1/m * np.matmul(X1.T,dz)\n",
        "  db = np.sum(dz)\n",
        "\n",
        "  W = W - lr*dw\n",
        "  b = b - lr*db\n",
        "\n",
        "  if epoch % 100 == 0:\n",
        "    print(logistic_loss)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6931471805599453\n",
            "0.38620494207634004\n",
            "0.3860274480581858\n",
            "0.38585412082216514\n",
            "0.38568486020224424\n",
            "0.3855195687922301\n",
            "0.38535815184534605\n",
            "0.3852005171781922\n",
            "0.3850465750789379\n",
            "0.38489623821959074\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LoENvIV5zIXg",
        "colab_type": "text"
      },
      "source": [
        "Linear regression using L1 regualrization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDszNPKLzIx1",
        "colab_type": "code",
        "outputId": "17570ba9-9ba8-4278-b5a3-36940602cd39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X = df.iloc[:,0].values\n",
        "#print(X)\n",
        "y = df.iloc[:,5].values\n",
        "m = 0\n",
        "b = 0\n",
        "l = 0.001\n",
        "epochs = 100\n",
        "lam = 0.1\n",
        " \n",
        "n = float(len(X))\n",
        "for i in range(epochs):\n",
        "  y_p = m*X + b\n",
        "  loss = np.sum(y_p - y1)**2 + (lam * m)\n",
        "  dv1 = (-2/n) * sum(X * (y - y_p)) + lam\n",
        "  dv0 = (-2/n) * sum(y - y_p)\n",
        "  m = m - (l*dv1)\n",
        "  b = b - (l*dv0)\n",
        "\n",
        "print(m,b)\n",
        "\n",
        "\n"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.07616351324952372 0.19219091824602255\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0Uel4a4zP39",
        "colab_type": "text"
      },
      "source": [
        "Linear regression using L2 regualrization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nr6WdypnzQTk",
        "colab_type": "code",
        "outputId": "d96de781-3972-4ffb-ccd6-d4d3df49ea0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X = df.iloc[:,0].values\n",
        "#print(X)\n",
        "y = df.iloc[:,5].values\n",
        "m = 0\n",
        "b = 0\n",
        "l = 0.001\n",
        "epochs = 100\n",
        "lam = 0.1\n",
        " \n",
        "n = float(len(X))\n",
        "for i in range(epochs):\n",
        "  y_p = m*X + b\n",
        "  loss = np.sum(y_p - y1)**2 + ((lam/2) * m)\n",
        "  dv1 = (-2/n) * sum(X * (y - y_p)) + (lam *m)\n",
        "  dv0 = (-2/n) * sum(y - y_p)\n",
        "  m = m - (l*dv1)\n",
        "  b = b - (l*dv0)\n",
        "\n",
        "print(m,b)\n"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.08496093383518896 0.19217387535350822\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZqTphNDzWWI",
        "colab_type": "text"
      },
      "source": [
        "Logistic regression using L1 regualrization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7F6RrmazW_7",
        "colab_type": "code",
        "outputId": "63fbec65-1226-4191-ba45-34aff6edc2a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        }
      },
      "source": [
        "X1 = df1.iloc[:,0:5].values\n",
        "y1 = df1.iloc[:,5].values\n",
        "lam = 0.1\n",
        "def sigmoid(Z):\n",
        "  return 1 /(1+np.exp(-Z))\n",
        "\n",
        "def loss(y1,y_hat):\n",
        "  return -np.mean(y1*np.log(y_hat) + (1-y1)*(np.log(1-y_hat))) + (lam * (np.sum(W)))\n",
        "\n",
        "W = np.zeros((5,1))\n",
        "b = np.zeros((1,1))\n",
        "\n",
        "m = len(y1)\n",
        "lr = 0.001\n",
        "for epoch in range(1000):\n",
        "  Z = np.matmul(X1,W)+b\n",
        "  A = sigmoid(Z)\n",
        "  logistic_loss = loss(y1,A)\n",
        "  dz = A - y1\n",
        "  dw = 1/m * np.matmul(X1.T,dz) + lam\n",
        "  db = np.sum(dz)\n",
        "\n",
        "  W = W - lr*dw\n",
        "  b = b - lr*db\n",
        "\n",
        "  if epoch % 100 == 0:\n",
        "    print(logistic_loss)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6931471805599453\n",
            "-0.11137508371210758\n",
            "-0.603431221426382\n",
            "-1.0901337704740328\n",
            "-1.5715502520079525\n",
            "-2.0477490724783447\n",
            "-2.5187993839773326\n",
            "-2.9847709510530773\n",
            "-3.445734024040758\n",
            "-3.901759218918095\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2rQgNvyzdHF",
        "colab_type": "text"
      },
      "source": [
        "**Logistic regression using L2 regualrization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H15MjKmqzdjq",
        "colab_type": "code",
        "outputId": "75fc98fe-e910-40f1-d919-d2e748fbcf13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        }
      },
      "source": [
        "X1 = df1.iloc[:,0:5].values\n",
        "y1 = df1.iloc[:,5].values\n",
        "lam = 0.1\n",
        "def sigmoid(Z):\n",
        "  return 1 /(1+np.exp(-Z))\n",
        "\n",
        "def loss(y1,y_hat):\n",
        "  return -np.mean(y1*np.log(y_hat) + (1-y1)*(np.log(1-y_hat))) + (lam * (np.sum(np.square(W))))\n",
        "\n",
        "W = np.zeros((5,1))\n",
        "b = np.zeros((1,1))\n",
        "\n",
        "m = len(y1)\n",
        "lr = 0.001\n",
        "for epoch in range(1000):\n",
        "  Z = np.matmul(X1,W)+b\n",
        "  A = sigmoid(Z)\n",
        "  logistic_loss = loss(y1,A)\n",
        "  dz = A - y1\n",
        "  dw = 1/m * np.matmul(X1.T,dz) + lam * W\n",
        "  db = np.sum(dz)\n",
        "\n",
        "  W = W - lr*dw\n",
        "  b = b - lr*db\n",
        "\n",
        "  if epoch % 100 == 0:\n",
        "    print(logistic_loss)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6931471805599453\n",
            "0.47138518391674106\n",
            "0.47465172002094635\n",
            "0.4809280022322704\n",
            "0.48996266375668274\n",
            "0.5015177834725313\n",
            "0.51536856679421\n",
            "0.5313030093974153\n",
            "0.5491215421136769\n",
            "0.5686366563832995\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "db60c1SLzmlY",
        "colab_type": "text"
      },
      "source": [
        "**K Means Clustering Algorithm**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opWChu6GznJV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class K_Means:\n",
        "    def __init__(self, k=2, tol=0.001, max_iter=300):\n",
        "        self.k = k\n",
        "        self.tol = tol\n",
        "        self.max_iter = max_iter\n",
        "\n",
        "    def fit(self,data):\n",
        "\n",
        "        self.centroids = {}\n",
        "\n",
        "        for i in range(self.k):\n",
        "            self.centroids[i] = data[i]\n",
        "\n",
        "        for i in range(self.max_iter):\n",
        "            self.classifications = {}\n",
        "\n",
        "            for i in range(self.k):\n",
        "                self.classifications[i] = []\n",
        "\n",
        "            for featureset in X:\n",
        "                distances = [np.linalg.norm(featureset-self.centroids[centroid]) for centroid in self.centroids]\n",
        "                classification = distances.index(min(distances))\n",
        "                self.classifications[classification].append(featureset)\n",
        "\n",
        "            prev_centroids = dict(self.centroids)\n",
        "\n",
        "            for classification in self.classifications:\n",
        "                self.centroids[classification] = np.average(self.classifications[classification],axis=0)\n",
        "\n",
        "            optimized = True\n",
        "\n",
        "            for c in self.centroids:\n",
        "                original_centroid = prev_centroids[c]\n",
        "                current_centroid = self.centroids[c]\n",
        "                if np.sum((current_centroid-original_centroid)/original_centroid*100.0) > self.tol:\n",
        "                    print(np.sum((current_centroid-original_centroid)/original_centroid*100.0))\n",
        "                    optimized = False\n",
        "\n",
        "            if optimized:\n",
        "                break\n",
        "\n",
        "    def predict(self,data):\n",
        "        distances = [np.linalg.norm(data-self.centroids[centroid]) for centroid in self.centroids]\n",
        "        classification = distances.index(min(distances))\n",
        "        return classification\n",
        "        \n",
        "colors = 10*[\"c\",\"b\",\"y\",\"p\",\"k\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7XLLQzuzvF4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = df3.iloc[:,0:2].values\n",
        "clf = K_Means()\n",
        "clf.fit(X)\n",
        "\n",
        "for centroid in clf.centroids:\n",
        "    plt.scatter(clf.centroids[centroid][0], clf.centroids[centroid][1],\n",
        "                marker=\"o\", color=\"k\", s=150, linewidths=5)\n",
        "\n",
        "for classification in clf.classifications:\n",
        "    color = colors[classification]\n",
        "    for featureset in clf.classifications[classification]:\n",
        "        plt.scatter(featureset[0], featureset[1], marker=\"x\", color=color, s=150, linewidths=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ljc6o24hz3J4",
        "colab_type": "text"
      },
      "source": [
        "**4th Problem statement**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26mpkOVvz3p2",
        "colab_type": "text"
      },
      "source": [
        "**Linear Regression from scratch using OOPS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTZy_8IGz4Qy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "class LinearRegressionModel():\n",
        "\n",
        "    def __init__(self, dataset, learning_rate, num_iterations):\n",
        "        self.dataset = np.array(dataset)\n",
        "        self.b = 0  \n",
        "        self.m = 0  \n",
        "        self.learning_rate = learning_rate\n",
        "        self.num_iterations = num_iterations\n",
        "        self.M = len(self.dataset)\n",
        "        self.total_error = 0\n",
        "\n",
        "    def apply_gradient_descent(self):\n",
        "        for i in range(self.num_iterations):\n",
        "            self.do_gradient_step()\n",
        "\n",
        "    def do_gradient_step(self):\n",
        "        b_summation = 0\n",
        "        m_summation = 0\n",
        "        for i in range(self.M):\n",
        "            x_value = self.dataset[i, 0]\n",
        "            y_value = self.dataset[i, 1]\n",
        "            b_summation += (((self.m * x_value) + self.b) - y_value) \n",
        "            m_summation += (((self.m * x_value) + self.b) - y_value) * x_value\n",
        "        self.b = self.b - (self.learning_rate * (1/self.M) * b_summation)\n",
        "        self.m = self.m - (self.learning_rate * (1/self.M) * m_summation)\n",
        "      \n",
        "    def compute_error(self):\n",
        "        for i in range(self.M):\n",
        "            x_value = self.dataset[i, 0]\n",
        "            y_value = self.dataset[i, 1]\n",
        "            self.total_error += ((self.m * x_value) + self.b) - y_value\n",
        "        return self.total_error\n",
        "\n",
        "    def __str__(self):\n",
        "        return \"Results: b: {}, m: {}, Final Total error: {}\".format(round(self.b, 2), round(self.m, 2), round(self.compute_error(), 2))\n",
        "\n",
        "    def get_prediction_based_on(self, x):\n",
        "        return round(float((self.m * x) + self.b), 2) # Type: Numpy float.\n",
        "\n",
        "def main():\n",
        "    school_dataset = np.genfromtxt(DATASET_PATH, delimiter=\",\")\n",
        "    lr = LinearRegressionModel(school_dataset, 0.0001, 1000)\n",
        "    lr.apply_gradient_descent()\n",
        "    hours = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
        "    for hour in hours:\n",
        "        print(\"Studied {} hours and got {} points.\".format(hour, lr.get_prediction_based_on(hour)))\n",
        "    print(lr)\n",
        "\n",
        "if __name__ == \"__main__\": main()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLZ03gA20CWo",
        "colab_type": "text"
      },
      "source": [
        "**Logistic Regression from scratch using OOPS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zVgQ6GV0C4r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LogisticRegression:\n",
        "  def __init__(self, learning_rate, num_iters, fit_intercept = True, verbose = False):\n",
        "    self.learning_rate = learning_rate\n",
        "    self.num_iters = num_iters\n",
        "    self.fit_intercept = fit_intercept\n",
        "    self.verbose = verbose\n",
        "  def __add_intercept(self, X):\n",
        "    intercept = np.ones((X.shape[0],1))\n",
        "    return np.concatenate((intercept,X),axis=1)\n",
        "  def __sigmoid(self,z):\n",
        "    return 1/(1+np.exp(-z))\n",
        "  def __loss(self, h, y):\n",
        "    return (-y * np.log(h) - (1-y) * np.log(1-h)).mean()\n",
        "  \n",
        "  def fit(self,X,y):\n",
        "    if self.fit_intercept:\n",
        "      X = self.__add_intercept(X)\n",
        "    self.theta = np.zeros(X.shape[1])\n",
        "    \n",
        "    for i in range(self.num_iters):\n",
        "      z = np.dot(X,self.theta)\n",
        "      h = self.__sigmoid(z)\n",
        "      gradient = np.dot(X.T,(h-y))/y.size\n",
        "      \n",
        "      self.theta -= self.learning_rate * gradient\n",
        "      \n",
        "      z = np.dot(X,self.theta)\n",
        "      h = self.__sigmoid(z)\n",
        "      loss = self.__loss(h,y)\n",
        "      \n",
        "      if self.verbose == True and i % 1000 == 0:\n",
        "        print(f'Loss: {loss}\\t')\n",
        "  def predict_probability(self,X):\n",
        "    if self.fit_intercept:\n",
        "      X = self.__add_intercept(X)\n",
        "    return self.__sigmoid(np.dot(X,self.theta))\n",
        "  def predict(self,X):\n",
        "    return (self.predict_probability(X).round())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4c6IVK8q0OF5",
        "colab_type": "text"
      },
      "source": [
        "**K Means from scratch using OOPS concepts**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q--Lswdp0Oi8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class K_Means:\n",
        "    def __init__(self, k=2, tol=0.001, max_iter=300):\n",
        "        self.k = k\n",
        "        self.tol = tol\n",
        "        self.max_iter = max_iter\n",
        "\n",
        "    def fit(self,data):\n",
        "\n",
        "        self.centroids = {}\n",
        "\n",
        "        for i in range(self.k):\n",
        "            self.centroids[i] = data[i]\n",
        "\n",
        "        for i in range(self.max_iter):\n",
        "            self.classifications = {}\n",
        "\n",
        "            for i in range(self.k):\n",
        "                self.classifications[i] = []\n",
        "\n",
        "            for featureset in X:\n",
        "                distances = [np.linalg.norm(featureset-self.centroids[centroid]) for centroid in self.centroids]\n",
        "                classification = distances.index(min(distances))\n",
        "                self.classifications[classification].append(featureset)\n",
        "\n",
        "            prev_centroids = dict(self.centroids)\n",
        "\n",
        "            for classification in self.classifications:\n",
        "                self.centroids[classification] = np.average(self.classifications[classification],axis=0)\n",
        "\n",
        "            optimized = True\n",
        "\n",
        "            for c in self.centroids:\n",
        "                original_centroid = prev_centroids[c]\n",
        "                current_centroid = self.centroids[c]\n",
        "                if np.sum((current_centroid-original_centroid)/original_centroid*100.0) > self.tol:\n",
        "                    print(np.sum((current_centroid-original_centroid)/original_centroid*100.0))\n",
        "                    optimized = False\n",
        "\n",
        "            if optimized:\n",
        "                break\n",
        "\n",
        "    def predict(self,data):\n",
        "        distances = [np.linalg.norm(data-self.centroids[centroid]) for centroid in self.centroids]\n",
        "        classification = distances.index(min(distances))\n",
        "        return classification\n",
        "        \n",
        "colors = 10*[\"c\",\"b\",\"y\",\"p\",\"k\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cHNR55Rvet3f"
      },
      "source": [
        ""
      ]
    }
  ]
}