{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab assignment 10.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8gixUa2ugw7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import style\n",
        "import numpy as np\n",
        "#from sklearn import preprocessing, cross_validation\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bnuXdTL249w",
        "colab_type": "text"
      },
      "source": [
        "**1st Problem statement**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57k1aFR6wvEA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "np.random.seed(123)\n",
        "\n",
        "allwalks = []\n",
        "\n",
        "for i in range(250):\n",
        "    randwalk = [0]\n",
        "    for x in range(100):\n",
        "        step = randwalk[-1]\n",
        "        dice = np.random.randint(1,7)\n",
        "        if dice <= 2 :\n",
        "            step = max(0, step - 1)\n",
        "\n",
        "        elif dice<=5:\n",
        "            step += 1\n",
        "\n",
        "        else:\n",
        "            step = step + np.random.randint(1,7)\n",
        "        \n",
        "    print(step)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "onBCC5T9xpRO",
        "colab_type": "text"
      },
      "source": [
        "**2nd Problem statment**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYQrnxTHx6gP",
        "colab_type": "text"
      },
      "source": [
        "**Random data for multiple linear regression**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3Oo46IByE6D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy\n",
        "import random\n",
        "from scipy.stats import norm\n",
        "random.seed(1)\n",
        "n_features = 4\n",
        "X = []\n",
        "for i in range(n_features):\n",
        "  X_i = scipy.stats.norm.rvs(0, 1, 100)\n",
        "  X.append(X_i)\n",
        "#print(X)\n",
        "eps = scipy.stats.norm.rvs(0, 0.25,100)\n",
        "y = 1 + (0.4 * X[0]) + eps + (0.5 * X[1]) + (0.3 * X[2]) + (0.4 * X[3])\n",
        "data_mlr = {'X0': X[0],'X1':X[1],'X2':X[2],'X3':X[3],'Y': y }\n",
        "df = pd.DataFrame(data_mlr)\n",
        "print(df.head())\n",
        "print(df.tail())\n",
        "print(df.info())\n",
        "print(df.describe())\n",
        "#df.to_csv('file1.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drCq2_yjyfMI",
        "colab_type": "text"
      },
      "source": [
        "**Random data for logistic regression**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7-8s-Tryf0U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_features = 4\n",
        "X = []\n",
        "for i in range(n_features):\n",
        "  X_i = scipy.stats.norm.rvs(0, 1, 100)\n",
        "  X.append(X_i)\n",
        "#print(X)\n",
        "a1 = (np.exp(1 + (0.5 * X[0]) + (0.4 * X[1]) + (0.3 * X[2]) + (0.5 * X[3]))/(1 + np.exp(1 + (0.5 * X[0]) + (0.4 * X[1]) + (0.3 * X[2]) + (0.5 * X[3]))))\n",
        "#print(a1)\n",
        "y1 = []\n",
        "for i in a1:\n",
        "  if (i>=0.5):\n",
        "    y1.append(1)\n",
        "  else:\n",
        "    y1.append(0)\n",
        "#print(y1)\n",
        "data_lr = {'X0': X[0],'X1':X[1],'X2':X[2],'X3':X[3],'Y': y1 }\n",
        "df1 = pd.DataFrame(data_lr)\n",
        "print(df1.head())\n",
        "print(df1.tail())\n",
        "print(df1.info())\n",
        "print(df1.describe())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbplkPfuyqqx",
        "colab_type": "text"
      },
      "source": [
        "**Random data for K means clustering**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jj_2yGgyrgp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 815
        },
        "outputId": "86a160bb-eeb5-4960-c498-f26232b9ada2"
      },
      "source": [
        "X_a= -2 * np.random.rand(100,2)\n",
        "X_b = 1 + 2 * np.random.rand(50,2)\n",
        "X_a[50:100, :] = X_b\n",
        "plt.scatter(X_a[ : , 0], X_a[ :, 1], s = 50)\n",
        "plt.show()\n",
        "data_kmeans = {'X0': X_a[:,0],'X1':X_a[:,1]}\n",
        "df3 = pd.DataFrame(data_kmeans)\n",
        "print(df3.head())\n",
        "print(df3.tail())\n",
        "print(df3.info())\n",
        "print(df3.describe())"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "         X0        X1\n",
            "0 -0.439029 -1.425859\n",
            "1 -0.985709 -0.923332\n",
            "2 -0.687021 -0.451348\n",
            "3 -1.756376 -0.449062\n",
            "4 -1.813224 -1.171191\n",
            "          X0        X1\n",
            "95  2.939853  1.810947\n",
            "96  1.186396  2.179446\n",
            "97  2.208860  1.261319\n",
            "98  1.210466  2.840515\n",
            "99  2.839544  2.284540\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 100 entries, 0 to 99\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   X0      100 non-null    float64\n",
            " 1   X1      100 non-null    float64\n",
            "dtypes: float64(2)\n",
            "memory usage: 1.7 KB\n",
            "None\n",
            "               X0          X1\n",
            "count  100.000000  100.000000\n",
            "mean     0.472882    0.573777\n",
            "std      1.585833    1.631607\n",
            "min     -1.992684   -1.966130\n",
            "25%     -1.008860   -0.972040\n",
            "50%      0.503720    0.493607\n",
            "75%      1.885717    1.976838\n",
            "max      2.939853    2.999077\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iV5fdCVyzl6",
        "colab_type": "text"
      },
      "source": [
        "**3rd problem statement**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GbtA18myy6qb",
        "colab_type": "text"
      },
      "source": [
        "**Linear regression using Gradient descent**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96Iph78fy7Mf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "73318276-5d1b-41b5-b5a3-1df5f53132b3"
      },
      "source": [
        "X = df.iloc[:,0].values\n",
        "#print(X)\n",
        "y = df.iloc[:,4].values\n",
        "b1 = 0\n",
        "b0 = 0\n",
        "l = 0.001\n",
        "epochs = 100\n",
        " \n",
        "n = float(len(X))\n",
        "for i in range(epochs):\n",
        "  y_p = b1*X + b0\n",
        "  loss = np.sum(y_p - y1)**2\n",
        "  d1 = (-2/n) * sum(X * (y - y_p))\n",
        "  d0 = (-2/n) * sum(y - y_p)\n",
        "  b1 = b1 - (l*d1)\n",
        "  b0 = b0 - (l*d0)\n",
        "\n",
        "print(b1,b0)\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.08297726333408594 0.18006939723867305\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wr8BOKGry9J0",
        "colab_type": "text"
      },
      "source": [
        "**Logistic regression using Gradient descent**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "peiWsLQky9g9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "outputId": "a4137c48-3169-495c-c436-e64aafe7d601"
      },
      "source": [
        "X1 = df1.iloc[:,0:4].values\n",
        "y1 = df1.iloc[:,4].values\n",
        "\n",
        "def sigmoid(Z):\n",
        "  return 1 /(1+np.exp(-Z))\n",
        "\n",
        "def loss(y1,y_hat):\n",
        "  return -np.mean(y1*np.log(y_hat) + (1-y1)*(np.log(1-y_hat)))\n",
        "\n",
        "W = np.zeros((4,1))\n",
        "b = np.zeros((1,1))\n",
        "\n",
        "m = len(y1)\n",
        "lr = 0.001\n",
        "for epoch in range(1000):\n",
        "  Z = np.matmul(X1,W)+b\n",
        "  A = sigmoid(Z)\n",
        "  logistic_loss = loss(y1,A)\n",
        "  dz = A - y1\n",
        "  dw = 1/m * np.matmul(X1.T,dz)\n",
        "  db = np.sum(dz)\n",
        "\n",
        "  W = W - lr*dw\n",
        "  b = b - lr*db\n",
        "\n",
        "  if epoch % 100 == 0:\n",
        "    print(logistic_loss)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6931471805599453\n",
            "0.4038817505870492\n",
            "0.4028319093088873\n",
            "0.4018135662477166\n",
            "0.40082630712090966\n",
            "0.3998696947179652\n",
            "0.39894326808188363\n",
            "0.39804654207159185\n",
            "0.3971790073169705\n",
            "0.39634013056778944\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LoENvIV5zIXg",
        "colab_type": "text"
      },
      "source": [
        "Linear regression using L1 regualrization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDszNPKLzIx1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a21e865b-ead4-4953-c736-752dec5024d0"
      },
      "source": [
        "X = df.iloc[:,0].values\n",
        "#print(X)\n",
        "y = df.iloc[:,4].values\n",
        "b1 = 0\n",
        "b0 = 0\n",
        "l = 0.001\n",
        "epochs = 100\n",
        "lam = 0.1\n",
        " \n",
        "n = float(len(X))\n",
        "for i in range(epochs):\n",
        "  y_p = b1*X + b0\n",
        "  loss = np.sum(y_p - y1)**2 + (lam * b1)\n",
        "  d1 = (-2/n) * sum(X * (y - y_p)) + lam\n",
        "  d0 = (-2/n) * sum(y - y_p)\n",
        "  b1 = b1 - (l*d1)\n",
        "  b0 = b0 - (l*d0)\n",
        "\n",
        "print(b1,b0)\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0738712823591653 0.18008044130900397\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0Uel4a4zP39",
        "colab_type": "text"
      },
      "source": [
        "Linear regression using L2 regualrization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nr6WdypnzQTk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f5dea2f0-8cff-4bfd-d293-6034d5691a4f"
      },
      "source": [
        "X = df.iloc[:,0].values\n",
        "#print(X)\n",
        "y = df.iloc[:,4].values\n",
        "b1 = 0\n",
        "b0 = 0\n",
        "l = 0.001\n",
        "epochs = 100\n",
        "lam = 0.1\n",
        " \n",
        "n = float(len(X))\n",
        "for i in range(epochs):\n",
        "  y_p = b1*X + b0\n",
        "  loss = np.sum(y_p - y1)**2 + ((lam/2) * b1)\n",
        "  d1 = (-2/n) * sum(X * (y - y_p)) + (lam *b1)\n",
        "  d0 = (-2/n) * sum(y - y_p)\n",
        "  b1 = b1 - (l*d1)\n",
        "  b0 = b0 - (l*d0)\n",
        "\n",
        "print(b1,b0)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.08257998381739863 0.1800697210778034\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZqTphNDzWWI",
        "colab_type": "text"
      },
      "source": [
        "Logistic regression using L1 regualrization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7F6RrmazW_7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "outputId": "83b713e4-293b-44ec-dd64-b627531d65a8"
      },
      "source": [
        "X1 = df1.iloc[:,0:4].values\n",
        "y1 = df1.iloc[:,4].values\n",
        "lam = 0.1\n",
        "def sigmoid(Z):\n",
        "  return 1 /(1+np.exp(-Z))\n",
        "\n",
        "def loss(y1,y_hat):\n",
        "  return -np.mean(y1*np.log(y_hat) + (1-y1)*(np.log(1-y_hat))) + (lam * (np.sum(W)))\n",
        "\n",
        "W = np.zeros((4,1))\n",
        "b = np.zeros((1,1))\n",
        "\n",
        "m = len(y1)\n",
        "lr = 0.001\n",
        "for epoch in range(1000):\n",
        "  Z = np.matmul(X1,W)+b\n",
        "  A = sigmoid(Z)\n",
        "  logistic_loss = loss(y1,A)\n",
        "  dz = A - y1\n",
        "  dw = 1/m * np.matmul(X1.T,dz) + lam\n",
        "  db = np.sum(dz)\n",
        "\n",
        "  W = W - lr*dw\n",
        "  b = b - lr*db\n",
        "\n",
        "  if epoch % 100 == 0:\n",
        "    print(logistic_loss)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6931471805599453\n",
            "0.005627403091365557\n",
            "-0.38866525731530316\n",
            "-0.7785099133890219\n",
            "-1.1639874680940294\n",
            "-1.5451782557334988\n",
            "-1.9221619214330494\n",
            "-2.295017312851155\n",
            "-2.663822383546498\n",
            "-3.0286541074087983\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2rQgNvyzdHF",
        "colab_type": "text"
      },
      "source": [
        "**Logistic regression using L2 regualrization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H15MjKmqzdjq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "outputId": "2524bcbe-589e-46d9-ec14-a70904a66499"
      },
      "source": [
        "X1 = df1.iloc[:,0:4].values\n",
        "y1 = df1.iloc[:,4].values\n",
        "lam = 0.1\n",
        "def sigmoid(Z):\n",
        "  return 1 /(1+np.exp(-Z))\n",
        "\n",
        "def loss(y1,y_hat):\n",
        "  return -np.mean(y1*np.log(y_hat) + (1-y1)*(np.log(1-y_hat))) + (lam * (np.sum(np.square(W))))\n",
        "\n",
        "W = np.zeros((4,1))\n",
        "b = np.zeros((1,1))\n",
        "\n",
        "m = len(y1)\n",
        "lr = 0.001\n",
        "for epoch in range(1000):\n",
        "  Z = np.matmul(X1,W)+b\n",
        "  A = sigmoid(Z)\n",
        "  logistic_loss = loss(y1,A)\n",
        "  dz = A - y1\n",
        "  dw = 1/m * np.matmul(X1.T,dz) + lam * W\n",
        "  db = np.sum(dz)\n",
        "\n",
        "  W = W - lr*dw\n",
        "  b = b - lr*db\n",
        "\n",
        "  if epoch % 100 == 0:\n",
        "    print(logistic_loss)\n",
        "\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6931471805599453\n",
            "0.4049582381035769\n",
            "0.4070322875898494\n",
            "0.4110320657537498\n",
            "0.4168107591568584\n",
            "0.42422822137927124\n",
            "0.4331508591929805\n",
            "0.4434515173335084\n",
            "0.4550093596939461\n",
            "0.4677097451328721\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "db60c1SLzmlY",
        "colab_type": "text"
      },
      "source": [
        "**K Means Clustering Algorithm**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opWChu6GznJV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class K_Means:\n",
        "    def __init__(self, k=2, tol=0.001, max_iter=300):\n",
        "        self.k = k\n",
        "        self.tol = tol\n",
        "        self.max_iter = max_iter\n",
        "\n",
        "    def fit(self,data):\n",
        "\n",
        "        self.centroids = {}\n",
        "\n",
        "        for i in range(self.k):\n",
        "            self.centroids[i] = data[i]\n",
        "\n",
        "        for i in range(self.max_iter):\n",
        "            self.classifications = {}\n",
        "\n",
        "            for i in range(self.k):\n",
        "                self.classifications[i] = []\n",
        "\n",
        "            for featureset in X:\n",
        "                distances = [np.linalg.norm(featureset-self.centroids[centroid]) for centroid in self.centroids]\n",
        "                classification = distances.index(min(distances))\n",
        "                self.classifications[classification].append(featureset)\n",
        "\n",
        "            prev_centroids = dict(self.centroids)\n",
        "\n",
        "            for classification in self.classifications:\n",
        "                self.centroids[classification] = np.average(self.classifications[classification],axis=0)\n",
        "\n",
        "            optimized = True\n",
        "\n",
        "            for c in self.centroids:\n",
        "                original_centroid = prev_centroids[c]\n",
        "                current_centroid = self.centroids[c]\n",
        "                if np.sum((current_centroid-original_centroid)/original_centroid*100.0) > self.tol:\n",
        "                    print(np.sum((current_centroid-original_centroid)/original_centroid*100.0))\n",
        "                    optimized = False\n",
        "\n",
        "            if optimized:\n",
        "                break\n",
        "\n",
        "    def predict(self,data):\n",
        "        distances = [np.linalg.norm(data-self.centroids[centroid]) for centroid in self.centroids]\n",
        "        classification = distances.index(min(distances))\n",
        "        return classification\n",
        "        \n",
        "colors = 10*[\"c\",\"b\",\"y\",\"p\",\"k\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7XLLQzuzvF4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "outputId": "5dc1f6dd-0325-4c21-c1b2-8096fc82e20b"
      },
      "source": [
        "X = df3.iloc[:,0:2].values\n",
        "clf = K_Means()\n",
        "clf.fit(X)\n",
        "\n",
        "for centroid in clf.centroids:\n",
        "    plt.scatter(clf.centroids[centroid][0], clf.centroids[centroid][1],\n",
        "                marker=\"o\", color=\"k\", s=150, linewidths=5)\n",
        "\n",
        "for classification in clf.classifications:\n",
        "    color = colors[classification]\n",
        "    for featureset in clf.classifications[classification]:\n",
        "        plt.scatter(featureset[0], featureset[1], marker=\"x\", color=color, s=150, linewidths=5)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ljc6o24hz3J4",
        "colab_type": "text"
      },
      "source": [
        "**4th Problem statement**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26mpkOVvz3p2",
        "colab_type": "text"
      },
      "source": [
        "**Linear Regression from scratch using OOPS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTZy_8IGz4Qy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "class LinearRegressionModel():\n",
        "\n",
        "    def __init__(self, dataset, learning_rate, num_iterations):\n",
        "        self.dataset = np.array(dataset)\n",
        "        self.b = 0  \n",
        "        self.m = 0  \n",
        "        self.learning_rate = learning_rate\n",
        "        self.num_iterations = num_iterations\n",
        "        self.M = len(self.dataset)\n",
        "        self.total_error = 0\n",
        "\n",
        "    def apply_gradient_descent(self):\n",
        "        for i in range(self.num_iterations):\n",
        "            self.do_gradient_step()\n",
        "\n",
        "    def do_gradient_step(self):\n",
        "        b_summation = 0\n",
        "        m_summation = 0\n",
        "        for i in range(self.M):\n",
        "            x_value = self.dataset[i, 0]\n",
        "            y_value = self.dataset[i, 1]\n",
        "            b_summation += (((self.m * x_value) + self.b) - y_value) \n",
        "            m_summation += (((self.m * x_value) + self.b) - y_value) * x_value\n",
        "        self.b = self.b - (self.learning_rate * (1/self.M) * b_summation)\n",
        "        self.m = self.m - (self.learning_rate * (1/self.M) * m_summation)\n",
        "      \n",
        "    def compute_error(self):\n",
        "        for i in range(self.M):\n",
        "            x_value = self.dataset[i, 0]\n",
        "            y_value = self.dataset[i, 1]\n",
        "            self.total_error += ((self.m * x_value) + self.b) - y_value\n",
        "        return self.total_error\n",
        "\n",
        "    def __str__(self):\n",
        "        return \"Results: b: {}, m: {}, Final Total error: {}\".format(round(self.b, 2), round(self.m, 2), round(self.compute_error(), 2))\n",
        "\n",
        "    def get_prediction_based_on(self, x):\n",
        "        return round(float((self.m * x) + self.b), 2) # Type: Numpy float.\n",
        "\n",
        "def main():\n",
        "    school_dataset = np.genfromtxt(DATASET_PATH, delimiter=\",\")\n",
        "    lr = LinearRegressionModel(school_dataset, 0.0001, 1000)\n",
        "    lr.apply_gradient_descent()\n",
        "    hours = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
        "    for hour in hours:\n",
        "        print(\"Studied {} hours and got {} points.\".format(hour, lr.get_prediction_based_on(hour)))\n",
        "    print(lr)\n",
        "\n",
        "if __name__ == \"__main__\": main()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLZ03gA20CWo",
        "colab_type": "text"
      },
      "source": [
        "**Logistic Regression from scratch using OOPS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zVgQ6GV0C4r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LogisticRegression:\n",
        "  def __init__(self, learning_rate, num_iters, fit_intercept = True, verbose = False):\n",
        "    self.learning_rate = learning_rate\n",
        "    self.num_iters = num_iters\n",
        "    self.fit_intercept = fit_intercept\n",
        "    self.verbose = verbose\n",
        "  def __add_intercept(self, X):\n",
        "    intercept = np.ones((X.shape[0],1))\n",
        "    return np.concatenate((intercept,X),axis=1)\n",
        "  def __sigmoid(self,z):\n",
        "    return 1/(1+np.exp(-z))\n",
        "  def __loss(self, h, y):\n",
        "    return (-y * np.log(h) - (1-y) * np.log(1-h)).mean()\n",
        "  \n",
        "  def fit(self,X,y):\n",
        "    if self.fit_intercept:\n",
        "      X = self.__add_intercept(X)\n",
        "    self.theta = np.zeros(X.shape[1])\n",
        "    \n",
        "    for i in range(self.num_iters):\n",
        "      z = np.dot(X,self.theta)\n",
        "      h = self.__sigmoid(z)\n",
        "      gradient = np.dot(X.T,(h-y))/y.size\n",
        "      \n",
        "      self.theta -= self.learning_rate * gradient\n",
        "      \n",
        "      z = np.dot(X,self.theta)\n",
        "      h = self.__sigmoid(z)\n",
        "      loss = self.__loss(h,y)\n",
        "      \n",
        "      if self.verbose == True and i % 1000 == 0:\n",
        "        print(f'Loss: {loss}\\t')\n",
        "  def predict_probability(self,X):\n",
        "    if self.fit_intercept:\n",
        "      X = self.__add_intercept(X)\n",
        "    return self.__sigmoid(np.dot(X,self.theta))\n",
        "  def predict(self,X):\n",
        "    return (self.predict_probability(X).round())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4c6IVK8q0OF5",
        "colab_type": "text"
      },
      "source": [
        "**K Means from scratch using OOPS concepts**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q--Lswdp0Oi8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class K_Means:\n",
        "    def __init__(self, k=2, tol=0.001, max_iter=300):\n",
        "        self.k = k\n",
        "        self.tol = tol\n",
        "        self.max_iter = max_iter\n",
        "\n",
        "    def fit(self,data):\n",
        "\n",
        "        self.centroids = {}\n",
        "\n",
        "        for i in range(self.k):\n",
        "            self.centroids[i] = data[i]\n",
        "\n",
        "        for i in range(self.max_iter):\n",
        "            self.classifications = {}\n",
        "\n",
        "            for i in range(self.k):\n",
        "                self.classifications[i] = []\n",
        "\n",
        "            for featureset in X:\n",
        "                distances = [np.linalg.norm(featureset-self.centroids[centroid]) for centroid in self.centroids]\n",
        "                classification = distances.index(min(distances))\n",
        "                self.classifications[classification].append(featureset)\n",
        "\n",
        "            prev_centroids = dict(self.centroids)\n",
        "\n",
        "            for classification in self.classifications:\n",
        "                self.centroids[classification] = np.average(self.classifications[classification],axis=0)\n",
        "\n",
        "            optimized = True\n",
        "\n",
        "            for c in self.centroids:\n",
        "                original_centroid = prev_centroids[c]\n",
        "                current_centroid = self.centroids[c]\n",
        "                if np.sum((current_centroid-original_centroid)/original_centroid*100.0) > self.tol:\n",
        "                    print(np.sum((current_centroid-original_centroid)/original_centroid*100.0))\n",
        "                    optimized = False\n",
        "\n",
        "            if optimized:\n",
        "                break\n",
        "\n",
        "    def predict(self,data):\n",
        "        distances = [np.linalg.norm(data-self.centroids[centroid]) for centroid in self.centroids]\n",
        "        classification = distances.index(min(distances))\n",
        "        return classification\n",
        "        \n",
        "colors = 10*[\"c\",\"b\",\"y\",\"p\",\"k\"]"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}